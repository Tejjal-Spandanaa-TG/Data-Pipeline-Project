
# Data Pipeline Automation Project

This project, developed during an internship at Gro Digitals, focuses on automating a data pipeline to extract, transform, and load customer data into a PostgreSQL database. The aim was to reduce manual effort, ensure data accuracy, and streamline reporting processes.

## Project Features
- **Automated Data Extraction**: Retrieves email attachments using IMAP.
- **Data Transformation**: Cleans and formats data using Python and Pandas.
- **Database Integration**: Creates and populates PostgreSQL tables.
- **Error Handling**: Implements mechanisms for robust data validation.
- **Automated Reporting**: Generates and sends reports via email using SMTP.

## Key Technologies
- **Python**: For scripting and automation.
- **Pandas**: For data manipulation.
- **PostgreSQL**: For database management.
- **IMAP/SMTP**: For email handling.

## Learning Outcomes
- Gained proficiency in Python for ETL processes.
- Explored database management with PostgreSQL and SQL.
- Built scalable and efficient data pipelines for real-world applications.


## How to Run the Project
1. Clone the repository.
2. Install the required Python libraries using `pip install -r requirements.txt`.
3. Configure the email server settings in the script.
4. Execute the pipeline script to extract, transform, and load data.
5. Use the reporting module to generate and email reports.
